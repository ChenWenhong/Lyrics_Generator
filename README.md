# Lyrics_Generator

Deep learning has shown great success in various applications in natural language processing (NLP). Text generation is a typical task in NLP area which includes, but not limited to, image captioning, text summarisation and dialogue generation. This project investigates the possibility of lyrics generation using a deep learning approach. Lyrics are a type of art which has rich emotional elements, well-defined structures and rhyme scheme. Thus, it is possible to apply deep neural network which is good at automatically extract the useful features to bridge the gap between computer generated and human written text. In this project, I use a particular neural network model called recurrent neural network Encoder-Decoder, also known as Sequence to Sequence model that consists of two word-based recurrent neural networks for generating a specific type of text, lyrics. This project resulted in one function. Users can gather the lyrics from different singers or provide their input text for training a generation model then synthesise the candidate lyrics text by giving words or sentences. By measuring the perplexity of the synthesised text, I determined a set of suitable parameters of the neural network model for avoiding the overfitting problem and getting a meaningful, well-structured result as far as possible. The final result proves that a Sequence to Sequence model containing Long Short-term memory units is a powerful tool when performing lyrics generation and other similar types of tasks.
